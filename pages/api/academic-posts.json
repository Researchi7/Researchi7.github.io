[
  {
    "id": 1,
    "name": "Conformal Prediction",
    "image": "./prompt_compression.jpeg",
    "description": "Prompt compression",
    "tags": ["LLM application", "MicroSoft"],
    "source_code": "https://github.com/MartinRepo",
    "fullText": "../aboutMe"
  },
  {
    "id": 2,
    "name": "LLM Benchmarking for Reading BioMed literatures",
    "image": "./benchmark_llm.jpeg",
    "description": "Benchmarking various LLMs, based on HPC",
    "tags": ["HPC", "PyTorch", "Generative-AI"],
    "source_code": "https://github.com/MartinRepo",
    "fullText": "../aboutMe"
  },
  {
    "id": 3,
    "name": "Llama3.cpp Local Deployment",
    "image": "./llama-cpp.png",
    "description": "A note of local deployment",
    "tags": ["Llama-cpp", "PyTorch", "Generative-AI"],
    "source_code": "https://github.com/MartinRepo",
    "fullText": "../aboutMe"
  },
  {
    "id": 4,
    "name": "LLM Quantisation Research",
    "image": "./quantisation.jpeg",
    "description": "Various of quantisation bit comparisons",
    "tags": ["HPC", "PyTorch", "LLM-Quantisation"],
    "source_code": "https://github.com/MartinRepo",
    "fullText": "../aboutMe"
  }
]
